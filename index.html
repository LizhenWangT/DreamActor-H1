<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="DreamActor-H1: High-Fidelity Human-Product Demonstration Video Generation via Motion-designed Diffusion Transformers.">
  <meta name="keywords" content="Animation, Diffusion Transformer, Video Generation">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>DreamActor-H1: High-Fidelity Human-Product Demonstration Video Generation via Motion-designed Diffusion Transformers</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>

  <style>
    .section {
      margin-top: 0rem; /* 增加章节之间的间距 */
      margin-bottom: 0rem; /* 增加章节之间的间距 */
    }

    .content {
      margin-bottom: 0rem; /* 减小章节内的间距 */
    }

    h2.title {
      margin-bottom: 0rem; /* 恢复章节标题和正文之间的间距 */
    }
  </style>
</head>
<body>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-2 publication-title"><span class="rainbow-text">DreamActor-H1</span>: High-Fidelity Human-Product Demonstration Video Generation via Motion-designed Diffusion Transformers</h1>
          <h1 class="title is-4 publication-title"></h1>
          <div class="is-size-5 publication-authors">

            <span class="author-block">
              <a href="">Lizhen Wang</a>,
            </span>
            <span class="author-block">
              <a href="">Zhurong Xia</a><sup>†</sup>,
            </span>
            <span class="author-block">
              <a href="">Tianshu Hu</a>,
            </span>
            <span class="author-block">
              <a href="">Pengrui Wang</a>,
            </span>
            <span class="author-block">
              <a href="">Pengfei Wei</a>,
            </span>
            <span class="author-block">
              <a href="">Zerong Zheng</a>,
            </span>
            <span class="author-block">
              <a href="">Ming Zhou</a>,
            </span>
            <span class="author-block">
              <a href="">Yuan Zhang</a>,
            </span>
            <span class="author-block">
              <a href="">Mingyuan Gao</a>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block">Bytedance Intelligent Creation</span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="eql-cntrb"><Small><sup>†</sup>Project Leader</Small></span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="eql-cntrb"><Small>{wanglizhen.2024, zhaogang.666, tianshu.hu, wangpengrui.chj, pengfei.wei, zerong, zhouming.9527}@bytedance.com, {zhang.yuan09,gaomingyuan001}@gmail.com</Small></span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2504.01724"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-fullhd">
    <div class="hero-body">
      <h2 class="subtitle has-text-justified">
        <p>
          We present <span class="dnerf">DreamActor-H1</span>, a novel Diffusion Transformer (DiT)-based framework that generates high-quality human-product demonstration videos from paired human and product images. Trained on a large-scale hybrid dataset with multi-class augmentation, DreamActor-H1 outperforms state-of-the-art methods in preserving human-product identity integrity and generating physically plausible demonstration motions, making it suitable for personalized e-commerce advertising and interactive media.
        </p>
      </h2>

      <div id="results-carousel" class="carousel results-carousel">
        <div class="item">
          <video id="teaser1" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/01.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item">
          <video id="teaser2" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/15.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item">
          <video id="teaser3" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/04.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item">
          <video id="teaser4" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/44.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item">
          <video id="teaser5" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/22.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item">
          <video id="teaser5" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/12.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item">
          <video id="teaser6" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/09.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item">
          <video id="teaser8" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/20.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item">
          <video id="teaser9" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/23.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item">
          <video id="teaser10" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/48.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item">
          <video id="teaser11" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/11.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item">
          <video id="teaser12" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/49.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item">
          <video id="teaser10" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/46.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item">
          <video id="teaser11" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/17.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item">
          <video id="teaser12" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/11.mp4" type="video/mp4">
          </video>
        </div>
      </div>

    </div>
  </div>
</section>



<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-4">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            In e-commerce and digital marketing, generating high-fidelity human-product demonstration videos is important for effective product presentation. However, most existing frameworks either fail to preserve the identities of both humans and products or lack an understanding of human-product spatial relationships, leading to unrealistic representations and unnatural interactions. To address these challenges, we propose a Diffusion Transformer (DiT)-based framework. Our method simultaneously preserves human identities and product-specific details, such as logos and textures, by injecting paired human-product reference information and utilizing an additional masked cross-attention mechanism. We employ a 3D body mesh template and product bounding boxes to provide precise motion guidance, enabling intuitive alignment of hand gestures with product placements. Additionally, structured text encoding is used to incorporate category-level semantics, enhancing 3D consistency during small rotational changes across frames. Trained on a hybrid dataset with extensive data augmentation strategies, our approach outperforms state-of-the-art techniques in maintaining the identity integrity of both humans and products and generating realistic demonstration motions.</p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Method Illustration. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-4">Method Overview</h2>
        <img src="./static/images/DreamActor-H1.jpeg"
         class="interpolation-image"
         alt="Interpolate start reference image."/>
        <div class="content has-text-justified">
        <p>
          Overview of <span class="dnerf">DreamActor-H1</span>. DreamActor-H1 can generate high-fidelity human-product demonstration videos from a human reference image and a product reference image. Our framework is built upon a DiT architecture, specifically leveraging Seaweed-7B, a foundational model for video generation with around 7 billion (7B) parameters. In the dataset preparation phase, we initially use a Vision-Language Model (VLM) to describe the product and human images. Subsequently, pose estimation and bounding box detection are applied to the training product-human demonstration video. During the training stage, we combine the human pose and product bounding box with the input video noise to serve as motion guidance. Additionally, we encode the input human and product images using a variational autoencoder (VAE) to serve as appearance guidance. The descriptions of the human and product are utilized as supplementary information, enhancing the material visual quality and 3D consistency during small rotational changes across frames. Regarding the DiT model, we implement stacks of full attention, reference attention, and object attention. Notably, object attention incorporates the product latent as an extra input. During the inference stage, we implement automatic pose template selection based on human and product information. Overall, our approach can overcome the challenges of identity preservation, motion realism, and spatial relationship modeling, and produce high-quality human-product demonstration videos given a human and a product image as inputs.
        </p>
      </div>
    </div>
    <!--/ Method Illustration. -->

    <!-- Paper video. -->
<!--     <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/MrKrnHhk8IA?rel=0&amp;showinfo=0"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div> -->
    <!--/ Paper video. -->
  </div>
</section>


<section class="section">
  <div class="container is-fullhd">
    <!-- Diversity Section -->
    <h2 class="title is-3">Diversity</h2>
    <div class="content has-text-justified">
      <p class="is-size-4">
        Our method is robust to various humans and products.
      </p>
    </div>

    <div id="diversity-carousel" class="carousel results-carousel">
      <div class="item">
        <video id="diversity1" autoplay controls muted loop playsinline height="100%">
          <source src="./static/videos/02.mp4" type="video/mp4">
        </video>
      </div>
      <div class="item">
        <video id="diversity2" autoplay controls muted loop playsinline height="100%">
          <source src="./static/videos/05.mp4" type="video/mp4">
        </video>
      </div>
      <div class="item">
        <video id="diversity3" autoplay controls muted loop playsinline height="100%">
          <source src="./static/videos/35.mp4" type="video/mp4">
        </video>
      </div>
      <div class="item">
        <video id="diversity3" autoplay controls muted loop playsinline height="100%">
          <source src="./static/videos/06.mp4" type="video/mp4">
        </video>
      </div>
      <div class="item">
        <video id="diversity4" autoplay controls muted loop playsinline height="100%">
          <source src="./static/videos/08.mp4" type="video/mp4">
        </video>
      </div>
      <div class="item">
        <video id="diversity5" autoplay controls muted loop playsinline height="100%">
          <source src="./static/videos/14.mp4" type="video/mp4">
        </video>
      </div>
      <div class="item">
        <video id="diversity6" autoplay controls muted loop playsinline height="100%">
          <source src="./static/videos/56.mp4" type="video/mp4">
        </video>
      </div>
      <div class="item">
        <video id="diversity7" autoplay controls muted loop playsinline height="100%">
          <source src="./static/videos/45.mp4" type="video/mp4">
        </video>
      </div>
      <div class="item">
        <video id="diversity8" autoplay controls muted loop playsinline height="100%">
          <source src="./static/videos/26.mp4" type="video/mp4">
        </video>
      </div>
      <div class="item">
        <video id="diversity9" autoplay controls muted loop playsinline height="100%">
          <source src="./static/videos/29.mp4" type="video/mp4">
        </video>
      </div>
      <div class="item">
        <video id="diversity10" autoplay controls muted loop playsinline height="100%">
          <source src="./static/videos/36.mp4" type="video/mp4">
        </video>
      </div>
      <div class="item">
        <video id="diversity10" autoplay controls muted loop playsinline height="100%">
          <source src="./static/videos/41.mp4" type="video/mp4">
        </video>
      </div>
      <div class="item">
        <video id="diversity11" autoplay controls muted loop playsinline height="100%">
          <source src="./static/videos/42.mp4" type="video/mp4">
        </video>
      </div>
    </div>

    <h2 class="title is-3" style="margin-top: 1rem;">Comparing to SOTA Methods</h2>
    
    <!-- 添加描述文字 -->
    <div class="content has-text-justified">
      <p class="is-size-4">
        Our method generates results with fine-grained product/human identity preservation, temporal consistency and high fidelity.
      </p>
    </div>

    <div class="content has-text-justified">
      <video id="ablation" autoplay controls muted loop playsinline height="100%">
        <source src="./static/videos/comparisons.mp4" type="video/mp4">
      </video>
    </div>

    <!-- Out-of-Distribution Section -->
    <h2 class="title is-3" style="margin-top: 4rem;">Ablation study</h2>

    <!-- 添加描述文字 -->
    <div class="content has-text-justified">
      <p class="is-size-4">
        We compare our full model with our full model w/o text input and our full model w/o text input and w/o object attention (baseline).
      </p>
    </div>
    <div class="content has-text-justified">
      <video id="ablation" autoplay controls muted loop playsinline height="100%">
        <source src="./static/videos/ablations.mp4" type="video/mp4">
      </video>
    </div>

  </div>
</section>




<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <h2 class="title is-4">Ethics Concerns</h2>
          <p>
            The human and product images used in demos are all generated by Seedream 3.0, except for three products from AnchorCrafter with their logos replaced.
          </p>
          
          <h2 class="title is-4">Acknowledgement</h2>
          <p>
            We would like to thank  <a href="https://nerfies.github.io/">Nerfies</a> for providing the website template.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>

